\section{Theory}
Most dMRI approaches in the context of dMRI are applying it to generate
probabilistic tractographies out of deterministic tracking approaches. Such
approaches are reviewed in Section XY. 

Our first novel contribution is to determine the uncertainty caused by
measurement errors in a systematical way. Wild bootstrapping is used to create
noisy resamples out of the measurements. The resampled data is then processed
and the parameters of a Bingham distribution are evaluated to measure the
uncertainty which is propagated through the dMRI pipeline. As a second
contribution we introduce a novel tracking approach, which calculates new
consensus directions based on the local directions obtained by the bootstrap
samples.  

\begin{itemize}
	\item Introduction to wild bootstrapping in our use case. E.g. Using
		bootstraps to calculate samples and calculate an mean fiber
		direction model. 
	\item Clustering 
	\item Show equivalent uncertainty maps
	\item Show that the variance is reduced if we use bootstrapping on the
		selection Model compared to the avg model. This justifies that
		the selection model stabilizes the computed directions even if
		noise is added. However for tracking it is better to keep all
		directions with adjusted length.
	\item Show the impact of bootstrapping by comparing the final direction
		main direction with the reference direction. Also compare the
		amount of fibers which is present in each voxel in case of the
		selection model.
	\item Compute also an alternative selection model. Here we use only the
		most potent fiber count over all bootstraps on voxel level.
		Justify this as restriction to measurement insecurity.
	\item Estimating Kent distribution -> See if there is a connection
		between the directions of a sample compared to the group means? 
\end{itemize}
\subsection{Wild Bootstrapping}
To evaluate the impact of measurement errors, we use use wild bootstrapping. It
has been shown that it is well suited within the context of dMRI many times and
is a straight forward way to
resample the original measurement without redo the measurement process
\cite{Jones:2008}.
As a first step the model is fitted to the data. We obtain a fODF
$\hat{\mathcal{T}}$ and can calculate residual of Eq. (\ref{eq:sd-min}) 
\[ \hat{\varepsilon} = S - M\hat{\mathcal{T}} .\] 
A new bootstrap realization is calculated by 
\[ y^{*} = M\hat{\mathcal{T}}  + \hat{\varepsilon} v , \]
where $v$ denotes the $n$ dimensional Rademacher distribution
 \[ v_i \left( k \right) \coloneqq  \begin{cases} \nicefrac{1}{2} \text{ if } k=-1 \\
	 \nicefrac{1}{2} \text{ if } k=1 \\
		0 \text { otherwise. } 
\end{cases} \]
 Finally the model is fitted to the bootstrap realization. This process is repeated $m$
times to create a sample size of $m$ bootstraps.
For each sampled fODF we calculate the low-rank approximation of rank $1$, $2$ and $3$
and with the obtained residuals also the selection and average model as it was
proposed by Gruen et al. \cite{Gruen:2021}. For each voxel we have build a
sampled set of fiber directions.  

As a first contribution we investigate the distribution of the selected rank
over all bootstrap. Therefore, in Fig. XY the in most bootstraps selected rank
is visualized and also the uncertainty is visualized by plotting the certain
\subsection{Bootstrap consensus Model}
Instead of using the bootstrap samples to produce a probability density map of
streamlines, we use it to reduce the measurement uncertainty by building a  bootstrap consensus model.
Therefore, the directions of all bootstraps get clustered to groups and the
group mean is the new direction.

To build a mean model we have to assign $n$ directions to $m$ groups on voxel
level. The group means are set to the directions of the original model. Now each
direction is assigned to a group such that the sum of angles between group mean
and direction is minimized over all possible assignments to the groups. In case
the original model recovers less directions than the bootstrap sample, we
prevent edge cases by assigning these bootstraps first and update the reference
direction. This does not lead to a global optimum but since we assume that the
directions are almost aligned it does lead to a good fit. 

To get deeper insights onto the impact of the bootstrapping we use the  Bingham 
distribution which is defined as follows: 
\begin{align*}
	B : \mathbb{S}^2 & \longrightarrow  \mathbb{R}_+ \\
	 	\mathbf{n} & \longmapsto   
	\frac{\exp \left( \mathbf{n}^T B \mathbf{n} \right)}{4 \pi {}_1F_1
	\left( \nicefrac{1}{2} , \nicefrac{3}{2} , B \right)} ,  
\end{align*}
with $B = R^T B_{diag} R$, ${}_1 F_1$ the confluent hypergeometric function, $R$
a rotation matrix that aligns around the main direction $\mu$ and $B_{diag} =
\text{Diag} \left( \zeta_1 , \zeta_2 , \zeta_3 \right)$. It is anisotropic density.

As it was proposed by Bingham the rotational matrix can be estimated by
calculating the eigenvectors of the samples covariance. Given $R$
the diagonal matrix $B_{diag}$ can be calculated by solving the
equation 
\[ 
	\frac{ \frac{\partial}{\partial \zeta_i} {}_1F_1 \left( \frac{1}{2} , \frac{3}{2} , \left( 
		\begin{matrix} 
			\zeta_1	& 0 \\
			0 & \zeta_2 
		\end{matrix}
\right) \right) }{ {}_1F_1 \left( \frac{1}{2} , \frac{3}{2} , \zeta_i \right) }
= \omega_i \text{ for } i = 1,2
\]
where $\omega_j$ are the eigenvalues belonging to the eigenvectors of the
rotation matrix and we force $\zeta_3 = 0$. Setting $\zeta_3=0$  is justified by the periodicity
of the Bingham distribution. 

In Fig. XY
$\kappa_1$ is plotted for the rank-$3$ approximation, the average model as well
as the selection model.


